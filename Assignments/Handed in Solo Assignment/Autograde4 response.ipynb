{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85147bca",
   "metadata": {
    "deletable": false
   },
   "source": [
    "\n",
    "# Assignment 4 for Course 1MS041\n",
    "Make sure you pass the `# ... Test` cells and\n",
    " submit your solution notebook in the corresponding assignment on the course website. You can submit multiple times before the deadline and your highest score will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d8b71",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "source": [
    "---\n",
    "## Assignment 4, PROBLEM 1\n",
    "Maximum Points = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e1585d",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "source": [
    "\n",
    "    This time the assignment only consists of one problem, but we will do a more comprehensive analysis instead.\n",
    "\n",
    "Consider the dataset `Corona_NLP_train.csv` that you can get from the course website [git](https://github.com/datascience-intro/1MS041-2024/blob/main/notebooks/data/Corona_NLP_train.csv). The data is \"Coronavirus tweets NLP - Text Classification\" that can be found on [kaggle](https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification). The data has several columns, but we will only be working with `OriginalTweet`and `Sentiment`.\n",
    "\n",
    "1. [3p] Load the data and filter out those tweets that have `Sentiment`=`Neutral`. Let $X$ represent the `OriginalTweet` and let \n",
    "    $$\n",
    "        Y = \n",
    "        \\begin{cases}\n",
    "        1 & \\text{if sentiment is towards positive}\n",
    "        \\\\\n",
    "        0 & \\text{if sentiment is towards negative}.\n",
    "        \\end{cases}\n",
    "    $$\n",
    "    Put the resulting arrays into the variables $X$ and $Y$. Split the data into three parts, train/test/validation where train is 60% of the data, test is 15% and validation is 25% of the data. Do not do this randomly, this is to make sure that we all did the same splits (we are in this case assuming the data is IID as presented in the dataset). That is [train,test,validation] is the splitting layout.\n",
    "\n",
    "2. [4p] There are many ways to solve this classification problem. The first main issue to resolve is to convert the $X$ variable to something that you can feed into a machine learning model. For instance, you can first use [`CountVectorizer`](https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) as the first step. The step that comes after should be a `LogisticRegression` model, but for this to work you need to put together the `CountVectorizer` and the `LogisticRegression` model into a [`Pipeline`](https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline). Fill in the variable `model` such that it accepts the raw text as input and outputs a number $0$ or $1$, make sure that `model.predict_proba` works for this. **Hint: You might need to play with the parameters of LogisticRegression to get convergence, make sure that it doesn't take too long or the autograder might kill your code**\n",
    "3. [3p] Use your trained model and calculate the precision and recall on both classes. Fill in the corresponding variables with the answer.\n",
    "4. [3p] Let us now define a cost function\n",
    "    * A positive tweet that is classified as negative will have a cost of 1\n",
    "    * A negative tweet that is classified as positive will have a cost of 5\n",
    "    * Correct classifications cost 0\n",
    "    \n",
    "    complete filling the function `cost` to compute the cost of a prediction model under a certain prediction threshold (recall our precision recall lecture and the `predict_proba` function from trained models). \n",
    "\n",
    "5. [4p] Now, we wish to select the threshold of our classifier that minimizes the cost, fill in the selected threshold value in value `optimal_threshold`.\n",
    "6. [4p] With your newly computed threshold value, compute the cost of putting this model in production by computing the cost using the validation data. Also provide a confidence interval of the cost using Hoeffdings inequality with a 99% confidence.\n",
    "7. [3p] Let $t$ be the threshold you found and $f$ the model you fitted (one of the outputs of `predict_proba`), if we define the random variable\n",
    "    $$\n",
    "        C = (1-1_{f(X)\\geq t})Y+5(1-Y)1_{f(X) \\geq t}\n",
    "    $$\n",
    "    then $C$ denotes the cost of a randomly chosen tweet. In the previous step we estimated $\\mathbb{E}[C]$ using the empirical mean. However, since the threshold is chosen to minimize cost it is likely that $C=0$ or $C=1$ than $C=5$ as such it will have a low variance. Compute the empirical variance of $C$ on the validation set. What would be the confidence interval if we used Bennett's inequality instead of Hoeffding in point 6 but with the computed empirical variance as our guess for the variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e6fa33",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-12-20T22:09:54.024015Z",
     "iopub.status.busy": "2024-12-20T22:09:54.022572Z",
     "iopub.status.idle": "2024-12-20T22:09:54.694462Z",
     "shell.execute_reply": "2024-12-20T22:09:54.693600Z"
    },
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 20066 samples\n",
      "Testing set: 5017 samples\n",
      "Validation set: 8361 samples\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Load\n",
    "file_path = 'data/Corona_NLP_train.csv'  # Adjust the path if necessary\n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "filtered_data = data[data['Sentiment'] != 'Neutral']\n",
    "X = filtered_data['OriginalTweet'].values\n",
    "Y = np.where(filtered_data['Sentiment'].str.contains('Positive'), 1, 0)\n",
    "\n",
    "n_samples = len(X)\n",
    "train_end = int(n_samples * 0.6)\n",
    "test_end = int(n_samples * 0.75)\n",
    "\n",
    "X_train = X[:train_end]\n",
    "Y_train = Y[:train_end]\n",
    "X_test = X[train_end:test_end]\n",
    "Y_test = Y[train_end:test_end]\n",
    "X_valid = X[test_end:]\n",
    "Y_valid = Y[test_end:]\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Testing set: {len(X_test)} samples\")\n",
    "print(f\"Validation set: {len(X_valid)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "078fe203",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-12-20T22:09:54.699245Z",
     "iopub.status.busy": "2024-12-20T22:09:54.698859Z",
     "iopub.status.idle": "2024-12-20T22:09:58.246873Z",
     "shell.execute_reply": "2024-12-20T22:09:58.245628Z"
    },
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Predicted Probabilities: [[0.87770511 0.12229489]\n",
      " [0.99712846 0.00287154]\n",
      " [0.03468556 0.96531444]\n",
      " [0.79883756 0.20116244]\n",
      " [0.43896061 0.56103939]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', LogisticRegression(max_iter=200, solver='liblinear'))\n",
    "])\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "sample_probs = model.predict_proba(X_test[:5])\n",
    "print(\"Sample Predicted Probabilities:\", sample_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec6fd1d4",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-12-20T22:09:58.253454Z",
     "iopub.status.busy": "2024-12-20T22:09:58.252606Z",
     "iopub.status.idle": "2024-12-20T22:09:58.490805Z",
     "shell.execute_reply": "2024-12-20T22:09:58.489922Z"
    },
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Class 0): 0.8579595426561126\n",
      "Precision (Class 1): 0.8709442216551221\n",
      "Recall (Class 0): 0.8464208242950109\n",
      "Recall (Class 1): 0.8808997050147492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "precision_0 = precision_score(Y_test, Y_pred, pos_label=0)\n",
    "precision_1 = precision_score(Y_test, Y_pred, pos_label=1)\n",
    "recall_0 = recall_score(Y_test, Y_pred, pos_label=0)\n",
    "recall_1 = recall_score(Y_test, Y_pred, pos_label=1)\n",
    "\n",
    "print(f\"Precision (Class 0): {precision_0}\")\n",
    "print(f\"Precision (Class 1): {precision_1}\")\n",
    "print(f\"Recall (Class 0): {recall_0}\")\n",
    "print(f\"Recall (Class 1): {recall_1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10698374",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-12-20T22:09:58.494256Z",
     "iopub.status.busy": "2024-12-20T22:09:58.493912Z",
     "iopub.status.idle": "2024-12-20T22:09:58.665032Z",
     "shell.execute_reply": "2024-12-20T22:09:58.664204Z"
    },
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cost (Threshold=0.5): 0.4171815826190951\n"
     ]
    }
   ],
   "source": [
    "def cost(model, threshold, X, Y):\n",
    "    probabilities = model.predict_proba(X)[:, 1]\n",
    "    predictions = (probabilities >= threshold).astype(int)    \n",
    "    costs = np.where(\n",
    "        (predictions == 1) & (Y == 0), \n",
    "        5,\n",
    "        np.where(\n",
    "            (predictions == 0) & (Y == 1),\n",
    "            1,\n",
    "            0 \n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return costs.mean()\n",
    "example_cost = cost(model, threshold=0.5, X=X_test, Y=Y_test)\n",
    "print(f\"Average Cost (Threshold=0.5): {example_cost}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b21963ec",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-12-20T22:09:58.668550Z",
     "iopub.status.busy": "2024-12-20T22:09:58.668172Z",
     "iopub.status.idle": "2024-12-20T22:10:14.967684Z",
     "shell.execute_reply": "2024-12-20T22:10:14.966856Z"
    },
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.8\n",
      "Cost at Optimal Threshold: 0.27267291209886385\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.linspace(0, 1, 101)\n",
    "costs = [cost(model, threshold, X_test, Y_test) for threshold in thresholds]\n",
    "optimal_threshold_index = np.argmin(costs)\n",
    "optimal_threshold = thresholds[optimal_threshold_index]\n",
    "cost_at_optimal_threshold = costs[optimal_threshold_index]\n",
    "\n",
    "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
    "print(f\"Cost at Optimal Threshold: {cost_at_optimal_threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a1c5e6",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-12-20T22:10:14.972164Z",
     "iopub.status.busy": "2024-12-20T22:10:14.971752Z",
     "iopub.status.idle": "2024-12-20T22:10:15.250619Z",
     "shell.execute_reply": "2024-12-20T22:10:15.249722Z"
    },
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at Optimal Threshold (Validation): 0.27747877048199976\n",
      "99% Confidence Interval: (0.25967857077556256, 0.29527897018843696)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "cost_at_optimal_threshold_valid = cost(model, optimal_threshold, X_valid, Y_valid)\n",
    "n_valid = len(Y_valid)\n",
    "epsilon = math.sqrt((1 / (2 * n_valid)) * math.log(2 / 0.01))\n",
    "cost_interval_valid = (\n",
    "    cost_at_optimal_threshold_valid - epsilon,\n",
    "    cost_at_optimal_threshold_valid + epsilon\n",
    ")\n",
    "assert(type(cost_interval_valid) == tuple)\n",
    "assert(len(cost_interval_valid) == 2)\n",
    "\n",
    "print(f\"Cost at Optimal Threshold (Validation): {cost_at_optimal_threshold_valid}\")\n",
    "print(f\"99% Confidence Interval: {cost_interval_valid}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3bc0760",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-12-20T22:10:15.255106Z",
     "iopub.status.busy": "2024-12-20T22:10:15.254696Z",
     "iopub.status.idle": "2024-12-20T22:10:15.536970Z",
     "shell.execute_reply": "2024-12-20T22:10:15.536142Z"
    },
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Variance of C: 0.669407805320785\n",
      "Confidence Interval using Bennett's inequality: (0.24729531160092996, 0.30766222936306953)\n"
     ]
    }
   ],
   "source": [
    "probabilities_valid = model.predict_proba(X_valid)[:, 1]\n",
    "predictions_valid = (probabilities_valid >= optimal_threshold).astype(int)\n",
    "C = (1 - (predictions_valid)) * Y_valid + 5 * (1 - Y_valid) * predictions_valid\n",
    "\n",
    "variance_of_C = np.var(C, ddof=1) \n",
    "mean_C = np.mean(C)\n",
    "b = 5 \n",
    "n_valid = len(C)\n",
    "epsilon_bennett = math.sqrt((2 * variance_of_C * math.log(2 / 0.01)) / n_valid) + (b * math.log(2 / 0.01)) / (3 * n_valid)\n",
    "interval_of_C = (\n",
    "    mean_C - epsilon_bennett,\n",
    "    mean_C + epsilon_bennett\n",
    ")\n",
    "assert(type(interval_of_C) == tuple)\n",
    "assert(len(interval_of_C) == 2)\n",
    "\n",
    "print(f\"Empirical Variance of C: {variance_of_C}\")\n",
    "print(f\"Confidence Interval using Bennett's inequality: {interval_of_C}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "add14737",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-12-20T22:10:15.541623Z",
     "iopub.status.busy": "2024-12-20T22:10:15.541278Z",
     "iopub.status.idle": "2024-12-20T22:10:26.711508Z",
     "shell.execute_reply": "2024-12-20T22:10:26.710687Z"
    },
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "TEST",
    "lx_problem_number": "1",
    "lx_problem_points": "24",
    "lx_test_only": "True",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical error -3.999404973864529e-15\n",
      "Numerical error -3.999404973864529e-15\n",
      "Beginning tests for problem 1\n",
      "\n",
      "---------------------------------\n",
      "Beginning test for part1\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "X.shape is correct, it is (33444,)\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Y.shape is correct, it is (33444,)\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "X seems to be a list of strings\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Y contains the correct values {0,1}\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Shape of X_train correct it is (20066,)\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "Shape of X_test incorrect, should be (5016,)\n",
      "You got 0.1 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "Shape of X_valid incorrect, should be (8362,)\n",
      "You got 0.1 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Shape of Y_train correct it is (20066,)\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "Shape of Y_test incorrect, should be (5016,)\n",
      "You got 0.1 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "Shape of Y_valid incorrect, should be (8362,)\n",
      "You got 0.1 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "---------------------------------\n",
      "Beginning test for part2\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "Your model has a predict_proba method\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Your model has a predict method\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "The predict_proba method returns a numpy array\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "The predict method returns 0 or 1\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Your model does produce the correct output shape when predict_proba is called on X_train\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Your model outperforms the naive classifier (always 0) on the training data, at least we learned something\n",
      "-----Ending test---------\n",
      "\n",
      "---------------------------------\n",
      "Beginning test for part3\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "Your precision_0 is correct\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Your precision_1 is correct\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Your recall_0 is correct\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Your recall_1 is correct\n",
      "-----Ending test---------\n",
      "\n",
      "---------------------------------\n",
      "Beginning test for part4\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "Your cost function agreed with the reference within an error of 0.01 on a simple test\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Your cost function agreed with the reference within an error of 0.01 on the training data using your model\n",
      "-----Ending test---------\n",
      "\n",
      "---------------------------------\n",
      "Beginning test for part5\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "Your optimal threshold agreed with the reference (calculated with your cost function) within an error of 0.05\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Your cost at the optimal threshold agreed with the reference (calculated with your cost function) within an error of 0.1\n",
      "-----Ending test---------\n",
      "\n",
      "---------------------------------\n",
      "Beginning test for part6\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "Your cost at the optimal threshold agreed with the reference within an error of 0.01\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "The lower edge of the cost interval did not agree with reference within an error of 0.01\n",
      "You got 1.0 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "The upper edge of the cost interval did not agree with reference within an error of 0.01\n",
      "You got 1.0 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "---------------------------------\n",
      "Beginning test for part7\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "Your variance of C agreed with the reference within an error of 0.01\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "The lower edge of the C interval agreed with reference within an error of 0.01\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "The upper edge of the C interval agreed with reference within an error of 0.01\n",
      "-----Ending test---------\n",
      "\n",
      "\n",
      "All tests complete, you got = 22 points\n",
      "The number of points you have scored for this problem is 22 out of 24\n",
      " \n",
      " \n",
      " \n",
      "The number of points you have scored in total for this entire set of Problems is 22 out of 24\n"
     ]
    }
   ],
   "source": [
    "# ASSIGNMENT 4, TEST 1, POINTS 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3b916f",
   "metadata": {},
   "source": [
    "The number of points you have scored in total for this entire set of Problems is 22 out of 24."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "lx_assignment_number": 4,
  "lx_course_instance": "2024",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
